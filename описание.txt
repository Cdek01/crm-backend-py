Архитектура EAV-модели (слой базы данных)

Мой конструктор основан на четырех основных моделях в db/models.py, которые вместе эмулируют поведение обычной таблицы.

1. EntityType (Тип Сущности)
Аналог: SQL-таблица (CREATE TABLE ...).
Что хранит: Метаданные о "таблице", которую создал пользователь.
name: Системное имя (contracts, projects).
display_name: Человекочитаемое имя ("Договоры", "Проекты").
tenant_id: Ключевое поле. Гарантирует, что таблица "Проекты" одного клиента полностью изолирована от таблицы "Проекты" другого.

2. Attribute (Атрибут)
Аналог: Колонка в SQL-таблице (ALTER TABLE ... ADD COLUMN ...).
Что хранит: Метаданные о "колонке".
entity_type_id: Ссылка на родительскую таблицу (EntityType).
name: Системное имя (contract_sum).
display_name: Человекочитаемое имя ("Сумма договора").
value_type: Важнейшее поле. Определяет тип данных, который будет храниться (string, integer, float, date, time, boolean, select).

3. Entity (Сущность)
Аналог: Строка (запись) в SQL-таблице (INSERT INTO ...).
Что хранит: Представляет собой одну запись, но не содержит самих данных. Это просто "контейнер" для значений.
id: Уникальный идентификатор строки.
entity_type_id: Ссылка на таблицу, к которой принадлежит эта строка.
created_at, updated_at, position: Системные поля для отслеживания и сортировки.

4. AttributeValue (Значение Атрибута)
Аналог: Ячейка в SQL-таблице. Это "сердце" EAV.
Что хранит: Конкретное значение для одной "строки" и одной "колонки".
entity_id: Ссылка на "строку" (Entity), к которой относится это значение.
attribute_id: Ссылка на "колонку" (Attribute), к которой относится это значение.
value_string, value_integer, value_float и т.д.: Набор типизированных колонок. В зависимости от value_type родительского Attribute, значение записывается только в одну из этих колонок.
Как это работает вместе: Чтобы получить одну "строку" (например, Договор №123), ORM делает JOIN между Entity, AttributeValue и Attribute.

Архитектура API и сервисного слоя

Просто иметь модели недостаточно. Нужно предоставить удобный интерфейс для работы с ними.

1. /api/meta (Работа со структурой)
Отвечает за: Создание, чтение, удаление "таблиц" (EntityType) и "колонок" (Attribute).
Сервис: EAVService содержит методы create_entity_type, create_attribute_for_type и т.д.
Логика: Эти методы просто создают/удаляют записи в таблицах entity_types и attributes, соблюдая все проверки (уникальность имени в рамках тенанта, права доступа meta:manage).
Целостность: При создании EntityType автоматически создаются разрешения (data:view:...) и системные поля (creation_date), что обеспечивает консистентность.

2. /api/data (Работа с данными)
Отвечает за: CRUD-операции с "записями" (Entity и AttributeValue).
Сервис: EAVService содержит методы create_entity, update_entity, get_all_entities_for_type.
Логика: Эти методы выполняют самую сложную работу — "пивотирование" (pivoting).
При создании/обновлении (POST/PUT):
Принимают "плоский" JSON от фронтенда: {"contract_sum": 150.0, "is_signed": true}.
Находят EntityType по имени, получают метаданные всех его Attribute.
Создают один объект Entity.
Для каждого ключа в JSON (contract_sum, is_signed) находят соответствующий Attribute.
Смотрят на его value_type (float, boolean).
Создают объект AttributeValue, записывая значение в правильную колонку (value_float = 150.0, value_boolean = true).

При чтении (GET):
Выполняют обратный процесс.
Загружают один Entity и все связанные с ним AttributeValue.
Проходят по списку AttributeValue и "собирают" из них один "плоский" JSON-объект, который и отправляется фронтенду.
Обеспечение целостности данных
Это критически важный аспект, который я реализовал на нескольких уровнях.

1. Уровень Базы Данных (Constraints & Cascades)
FOREIGN KEY: Все связи (entity_type_id, tenant_id и т.д.) определены как внешние ключи. База данных просто не позволит создать AttributeValue, если не существует соответствующего Entity или Attribute.
UNIQUE constraint: Композитные уникальные ключи гарантируют, что у одного клиента не может быть двух таблиц или двух колонок с одинаковыми системными именами.
code
Python
# db/models.py -> EntityType
__table_args__ = (UniqueConstraint('name', 'tenant_id', ...),)
cascade="all, delete-orphan" и ondelete="CASCADE": Это самый важный механизм.
Пример: В модели EntityType связь с attributes определена как cascade="all, delete-orphan".
Что это значит: Если я удаляю EntityType (таблицу), SQLAlchemy и база данных автоматически удалят все связанные с ней Attribute (колонки), которые, в свою очередь, каскадно удалят все AttributeValue (значения в ячейках), связанные с этими колонками.
Это гарантирует, что в базе не останется "осиротевших" данных, которые ссылаются на несуществующие объекты.

2. Уровень Сервисного слоя (Бизнес-логика)
Проверка прав доступа: Перед любой операцией (создание, чтение, удаление) сервисный метод сначала проверяет tenant_id или права доступа пользователя. Например, метод delete_attribute_from_type сначала вызывает get_entity_type_by_id, чтобы убедиться, что пользователь имеет право работать с этой таблицей.
Валидация типов: Метод _process_value централизованно проверяет и преобразует данные перед записью в базу. Он не позволит записать строку "abc" в числовое поле, предотвращая ошибки на уровне БД и обеспечивая чистоту данных.
Транзакционность: Все операции по изменению данных (например, create_entity, который создает Entity и множество AttributeValue) выполняются в рамках одной транзакции. Если при создании одного из AttributeValue произойдет сбой, вся транзакция откатится, и "недосозданная" запись не попадет в базу.




4. Pipeline асинхронной задачи на Celery и Redis
В проекте реализован pipeline для отправки SMS-уведомлений. Он спроектирован так, чтобы быть неблокирующим и устойчивым к сбоям.
Сценарий: Пользователь меняет значение в кастомной таблице, что должно инициировать отправку SMS.
Pipeline по шагам:
Инициация (API-слой):
Триггер: Пользователь отправляет PUT запрос на /api/data/{table_name}/{entity_id}, в теле которого есть "send_sms_trigger": true.
Действие: Метод update_entity в services/eav_service.py перехватывает этот флаг.
Первичная обработка: Он немедленно обновляет данные в словаре data, устанавливая sms_status в "pending" (в ожидании) и сбрасывая send_sms_trigger в false. Это предотвращает повторную отправку при случайном двойном клике.
Постановка в очередь (Интеграция с Celery):
Действие: Сразу после изменения статуса, update_entity вызывает .delay() для Celery-задачи:
code
Python
send_sms_for_entity_task.delay(
    entity_id=entity_id,
    user_id=current_user.id
)
Что происходит: Celery сериализует вызов этой функции и ее аргументы (entity_id и user_id) и отправляет это "сообщение" (задачу) в Redis, который выступает в роли брокера сообщений.
Результат для пользователя: API-эндпоинт не ждет выполнения задачи. Он сразу же сохраняет изменения в основной базе данных (статус "pending") и возвращает пользователю ответ 200 OK. Пользователь видит мгновенную реакцию интерфейса.
Выполнение (Celery Worker):
Воркер: На сервере работает отдельный, независимый процесс — Celery worker. Он постоянно "слушает" очередь в Redis.
Захват задачи: Как только в Redis появляется новая задача, воркер забирает ее.
Исполнение: Воркер выполняет код функции send_sms_for_entity_task из tasks/messaging.py.
Логика внутри задачи:
Получение контекста: Задача открывает собственное, новое соединение с базой данных. Используя user_id и entity_id, она загружает все необходимые данные: объект пользователя и данные сущности (включая номер телефона и текст сообщения).
Взаимодействие с внешним API: Задача вызывает wappi.api(...), который отправляет реальный HTTP-запрос во внешний сервис Wappi.pro.
Обработка результата:
Успех: Если wappi.api вернул False (нет ошибки), задача вызывает eav_service.update_entity, чтобы обновить статус записи в базе на "sent".
Ошибка: Если wappi.api вернул True (есть ошибка), или произошла ошибка сети, задача вызывает eav_service.update_entity и обновляет статус на "error", а также записывает текст ошибки в поле sms_last_error.

joinedload — это одна из самых важных и мощных опций для оптимизации запросов в SQLAlchemy.
Если коротко, joinedload позволяет загружать связанные данные одним SQL-запросом вместо нескольких, решая "проблему N+1".
Давайте разберем на простом примере.
Сценарий без joinedload (Проблема N+1)
Предположим, у нас есть модели User и Role, и нам нужно получить список всех пользователей и вывести имя роли для каждого.
Модели:
code
Python
class User(Base):
    # ...
    role_id = Column(Integer, ForeignKey('roles.id'))
    role = relationship("Role") # <-- Связь

class Role(Base):
    # ...
    name = Column(String)
Код для получения данных:
code
Python
# Получаем 10 пользователей
users = db.query(User).limit(10).all()

# Теперь выводим их имена и роли
for user in users:
    print(f"Пользователь: {user.email}, Роль: {user.role.name}")
Что происходит "под капотом" в базе данных:
Запрос 1: SQLAlchemy выполняет один запрос, чтобы получить 10 пользователей.
code
SQL
SELECT users.id, users.email, users.role_id FROM users LIMIT 10;
```2.  **Цикл `for` начинается**:
*   **Итерация 1**: Код доходит до `user.role.name`. SQLAlchemy видит, что данные для `role` еще не загружены. Он выполняет **второй** SQL-запрос:
    ```sql
    SELECT roles.id, roles.name FROM roles WHERE roles.id = <role_id_первого_юзера>;
    ```
*   **Итерация 2**: Код снова доходит до `user.role.name` для второго пользователя. SQLAlchemy выполняет **третий** SQL-запрос:
    ```sql
    SELECT roles.id, roles.name FROM roles WHERE roles.id = <role_id_второго_юзера>;
    ```
*   ... и так далее.
Результат: Чтобы получить данные для 10 пользователей, мы сделали 11 SQL-запросов (1 для пользователей + 10 для ролей). Если бы у нас было 1000 пользователей, мы бы сделали 1001 запрос. Это и есть "проблема N+1", и она катастрофически замедляет приложение.
Сценарий с joinedload (Решение)
Теперь используем joinedload, чтобы сказать SQLAlchemy: "Пожалуйста, будь умнее и загрузи все сразу".
Измененный код:
code
Python
from sqlalchemy.orm import joinedload

# Используем .options(joinedload(...))
users = db.query(User).options(
    joinedload(User.role)
).limit(10).all()

# Теперь выводим их имена и роли
for user in users:
    # Здесь НИКАКИХ новых запросов к базе не будет!
    print(f"Пользователь: {user.email}, Роль: {user.role.name}")
Что происходит "под капотом":
Запрос 1: SQLAlchemy видит joinedload(User.role) и генерирует один, но более сложный SQL-запрос с использованием LEFT JOIN:
code
SQL
SELECT
    users.id, users.email, users.role_id,
    roles_1.id AS roles_1_id, roles_1.name AS roles_1_name
FROM
    users
LEFT OUTER JOIN
    roles AS roles_1 ON roles_1.id = users.role_id
LIMIT 10;
Результат: SQLAlchemy получает все необходимые данные (и о пользователях, и об их ролях) за один поход в базу данных.
Цикл for начинается: Когда код доходит до user.role.name, все данные уже находятся в памяти, и никаких дополнительных запросов не требуется.
Результат: Чтобы получить данные для 10 или 1000 пользователей, мы сделали всего 1 SQL-запрос. Это огромный выигрыш в производительности.
Вложенная жадная загрузка
joinedload можно объединять в цепочки. В вашем коде мы использовали это для RBAC:
code
Python
db.query(models.User).options(
    joinedload(models.User.roles). # <-- Загрузи роли
    joinedload(models.Role.permissions) # <-- А для каждой роли сразу загрузи ее разрешения
).filter(...)
Это создает еще более сложный JOIN, но все равно выполняет всю работу за один запрос.
Итог
joinedload — это инструкция для SQLAlchemy, которая меняет стратегию загрузки связанных данных с "ленивой" (по запросу) на "жадную" (сразу), используя LEFT JOIN для объединения таблиц в одном SQL-запросе. Это основной инструмент для оптимизации ORM-запросов и решения проблемы N+1.